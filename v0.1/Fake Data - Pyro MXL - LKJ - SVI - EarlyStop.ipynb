{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN number: 2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import sys\n",
    "#RUN = int(sys.argv[1])\n",
    "RUN = 2\n",
    "print(\"RUN number:\", RUN)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import biogeme.database as db\n",
    "import seaborn as sns\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions.util import logsumexp\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TraceEnum_ELBO\n",
    "from pyro.infer.abstract_infer import TracePredictive\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal, AutoDiagonalNormal, AutoGuideList\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "import pyro.optim as optim\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  \n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fake data...\n",
      "Error: 46.28\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#Generate data\n",
    "###\n",
    "\n",
    "N = 500\n",
    "T = 5\n",
    "NT = N * T\n",
    "J = 5\n",
    "NTJ = NT * J\n",
    "\n",
    "L = 3 #no. of fixed paramters\n",
    "K = 5 #no. of random parameters\n",
    "\n",
    "true_alpha = np.array([-0.8, 0.8, 1.2])\n",
    "true_beta = np.array([-0.8, 0.8, 1.0, -0.8, 1.5])\n",
    "true_Omega = np.array([[1.0, 0.8, 0.8, 0.8, 0.8],\n",
    "                       [0.8, 1.0, 0.8, 0.8, 0.8],\n",
    "                       [0.8, 0.8, 1.0, 0.8, 0.8],\n",
    "                       [0.8, 0.8, 0.8, 1.0, 0.8],\n",
    "                       [0.8, 0.8, 0.8, 0.8, 1.0]])\n",
    "# dynamic version\n",
    "corr = 0.8\n",
    "scale_factor = 1.0\n",
    "true_Omega = corr*np.ones((K,K)) # off-diagonal values of cov matrix\n",
    "true_Omega[np.arange(K), np.arange(K)] = 1.0 # diagonal values of cov matrix\n",
    "true_Omega *= scale_factor\n",
    "\n",
    "print(\"Generating fake data...\")\n",
    "xFix = np.random.rand(NTJ, L)\n",
    "xRnd = np.random.rand(NTJ, K)\n",
    "\n",
    "betaInd_tmp = true_beta + \\\n",
    "(np.linalg.cholesky(true_Omega) @ np.random.randn(K, N)).T\n",
    "beta_tmp = np.kron(betaInd_tmp, np.ones((T * J,1)))\n",
    "\n",
    "eps = -np.log(-np.log(np.random.rand(NTJ,)))\n",
    "\n",
    "vDet = xFix @ true_alpha + np.sum(xRnd * beta_tmp, axis = 1)\n",
    "v = vDet + eps\n",
    "\n",
    "vDetMax = np.zeros((NT,))\n",
    "vMax = np.zeros((NT,))\n",
    "\n",
    "chosen = np.zeros((NTJ,), dtype = 'int64')\n",
    "\n",
    "for t in np.arange(NT):\n",
    "    l = t * J; u = (t + 1) * J\n",
    "    altMaxDet = np.argmax(vDet[l:u])\n",
    "    altMax = np.argmax(v[l:u])\n",
    "    vDetMax[t] = altMaxDet\n",
    "    vMax[t] = altMax\n",
    "    chosen[l + altMax] = 1\n",
    "\n",
    "error = np.sum(vMax == vDetMax) / NT * 100\n",
    "print(\"Error:\", error)\n",
    "\n",
    "indID = np.repeat(np.arange(N), T * J)\n",
    "obsID = np.repeat(np.arange(NT), J)\n",
    "altID = np.tile(np.arange(J), NT)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert fake data to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_alternatives = altID.max() + 1\n",
    "num_resp = indID.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # THIS IS SLOW!!! IF NOT CHANGED, IT IS FASTER TO READ THE PREVIOUS DATA FROM DISK\n",
    "    # convert long format to wide format\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ind in range(num_resp):\n",
    "        #print(\"------------------ individual:\", ind)\n",
    "        ind_ix = np.where(indID == ind)[0]\n",
    "        #print(\"ind_ix:\", ind_ix)\n",
    "        ind_xs = []\n",
    "        ind_ys = []\n",
    "        for n in np.unique(obsID[ind_ix]):\n",
    "            #print(\"--------- observation:\", n)\n",
    "            obs_ix = np.where(obsID == n)[0]\n",
    "            #print(\"obs_ix:\", obs_ix)\n",
    "\n",
    "            # get attributes (x)\n",
    "            x = [[] for i in range(num_alternatives)]\n",
    "            #print(\"altID:\", altID[obs_ix])\n",
    "            for alt in range(num_alternatives):\n",
    "                if alt in altID[obs_ix]:\n",
    "                    x[alt].append(np.hstack([xFix[obs_ix][alt], xRnd[obs_ix][alt]]))\n",
    "                else:\n",
    "                    x[alt].append(np.zeros(L+K))\n",
    "            x = np.hstack(x)[0]\n",
    "            #print(\"x:\", x)\n",
    "            ind_xs.append(x)\n",
    "\n",
    "            # get choice (y)\n",
    "            y = np.argmax(chosen[obs_ix])\n",
    "            #print(\"y:\", y)\n",
    "            ind_ys.append(y)\n",
    "\n",
    "        xs.append(np.array(ind_xs))\n",
    "        ys.append(np.array(ind_ys))\n",
    "\n",
    "    alt_availability = np.ones((N,T,J))\n",
    "    alt_attributes = np.array(xs)\n",
    "    true_choices = np.array(ys)\n",
    "    \n",
    "    np.savez('fakedata.npz', \n",
    "             alt_availability=alt_availability, \n",
    "             alt_attributes=alt_attributes, \n",
    "             true_choices=true_choices)\n",
    "else:\n",
    "    # load previously generated data from disk\n",
    "    data = np.load('fakedata.npz')\n",
    "    alt_availability = data['alt_availability']\n",
    "    alt_attributes = data['alt_attributes']\n",
    "    true_choices = data['true_choices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alt. availability: (500, 5, 5)\n",
      "Alt. attributes: (500, 5, 40)\n",
      "True choices: (500, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Alt. availability:\", alt_availability.shape)\n",
    "print(\"Alt. attributes:\", alt_attributes.shape)\n",
    "print(\"True choices:\", true_choices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and Mixed Logit specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. observations: 12500\n",
      "Num. alternatives: 5\n",
      "Parameter IDs to be treated in a Mixed Logit way: [3 4 5 6 7]\n",
      "Parameter IDs to be treated in a MNL way: [0 1 2]\n",
      "Utility functions:\n",
      "\tV_ALT1_n = beta0 * ALT1_XF1 + beta1 * ALT1_XF2 + beta2 * ALT1_XF3 + beta3_n * ALT1_XR1 + beta4_n * ALT1_XR2 + beta5_n * ALT1_XR3 + beta6_n * ALT1_XR4 + beta7_n * ALT1_XR5\n",
      "\tV_ALT2_n = beta0 * ALT2_XF1 + beta1 * ALT2_XF2 + beta2 * ALT2_XF3 + beta3_n * ALT2_XR1 + beta4_n * ALT2_XR2 + beta5_n * ALT2_XR3 + beta6_n * ALT2_XR4 + beta7_n * ALT2_XR5\n",
      "\tV_ALT3_n = beta0 * ALT3_XF1 + beta1 * ALT3_XF2 + beta2 * ALT3_XF3 + beta3_n * ALT3_XR1 + beta4_n * ALT3_XR2 + beta5_n * ALT3_XR3 + beta6_n * ALT3_XR4 + beta7_n * ALT3_XR5\n",
      "\tV_ALT4_n = beta0 * ALT4_XF1 + beta1 * ALT4_XF2 + beta2 * ALT4_XF3 + beta3_n * ALT4_XR1 + beta4_n * ALT4_XR2 + beta5_n * ALT4_XR3 + beta6_n * ALT4_XR4 + beta7_n * ALT4_XR5\n",
      "\tV_ALT5_n = beta0 * ALT5_XF1 + beta1 * ALT5_XF2 + beta2 * ALT5_XF3 + beta3_n * ALT5_XR1 + beta4_n * ALT5_XR2 + beta5_n * ALT5_XR3 + beta6_n * ALT5_XR4 + beta7_n * ALT5_XR5\n",
      "Num. parameters to be estimated: 8\n",
      "Num. attributes to be used in total: 40\n",
      "Num respondents: 500\n"
     ]
    }
   ],
   "source": [
    "# DCM specification\n",
    "num_obs = len(chosen)\n",
    "print(\"Num. observations:\", num_obs)\n",
    "\n",
    "alt_names = [\"ALT1\", \"ALT2\", \"ALT3\", \"ALT4\", \"ALT5\"]\n",
    "assert num_alternatives == len(alt_names)\n",
    "print(\"Num. alternatives:\", num_alternatives)\n",
    "\n",
    "attr_names = ['ALT1_XF1', 'ALT1_XF2','ALT1_XF3', 'ALT1_XR1', 'ALT1_XR2','ALT1_XR3', 'ALT1_XR4', 'ALT1_XR5', \n",
    "              'ALT2_XF1', 'ALT2_XF2','ALT2_XF3', 'ALT2_XR1', 'ALT2_XR2','ALT2_XR3', 'ALT2_XR4', 'ALT2_XR5', \n",
    "              'ALT3_XF1', 'ALT3_XF2','ALT3_XF3', 'ALT3_XR1', 'ALT3_XR2','ALT3_XR3', 'ALT3_XR4', 'ALT3_XR5', \n",
    "              'ALT4_XF1', 'ALT4_XF2','ALT4_XF3', 'ALT4_XR1', 'ALT4_XR2','ALT4_XR3', 'ALT4_XR4', 'ALT4_XR5', \n",
    "              'ALT5_XF1', 'ALT5_XF2','ALT5_XF3', 'ALT5_XR1', 'ALT5_XR2','ALT5_XR3', 'ALT5_XR4', 'ALT5_XR5', ] \n",
    "alt_ids = np.array([0,0,0,0,0,0,0,0,\n",
    "                    1,1,1,1,1,1,1,1,\n",
    "                    2,2,2,2,2,2,2,2,\n",
    "                    3,3,3,3,3,3,3,3,\n",
    "                    4,4,4,4,4,4,4,4]) # assigns attributes to IDs corresponding to alternatives\n",
    "param_ids = np.array([0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7]) # assigns attributes to IDs indicating parameters to be estimated\n",
    "mix_params = np.array([3,4,5,6,7]) # IDs of parameters to be treated with a Mixed Logit formulation\n",
    "non_mix_params = np.array([x for x in range(max(param_ids)+1) if x not in mix_params])\n",
    "print(\"Parameter IDs to be treated in a Mixed Logit way:\", mix_params)\n",
    "print(\"Parameter IDs to be treated in a MNL way:\", non_mix_params)\n",
    "\n",
    "# debug utility functions specified\n",
    "print(\"Utility functions:\")\n",
    "for i in range(num_alternatives):\n",
    "    v_ix = np.where(alt_ids == i)[0]\n",
    "    if param_ids[v_ix[0]] in mix_params:\n",
    "        s = \"\\tV_%s_n = beta%d_n * %s\" % (alt_names[i], param_ids[v_ix[0]], attr_names[v_ix[0]])\n",
    "    else:\n",
    "        s = \"\\tV_%s_n = beta%d * %s\" % (alt_names[i], param_ids[v_ix[0]], attr_names[v_ix[0]])\n",
    "    for j in range(1,len(v_ix)):\n",
    "        if param_ids[v_ix[j]] in mix_params:\n",
    "            s += \" + beta%d_n * %s\" % (param_ids[v_ix[j]], attr_names[v_ix[j]])\n",
    "        else:\n",
    "            s += \" + beta%d * %s\" % (param_ids[v_ix[j]], attr_names[v_ix[j]])\n",
    "    print(s)\n",
    "\n",
    "# further checks and definitions\n",
    "assert len(np.unique(param_ids)) == max(param_ids)+1\n",
    "assert min(param_ids) == 0\n",
    "num_params = max(param_ids) + 1\n",
    "print(\"Num. parameters to be estimated:\", num_params)\n",
    "D = len(attr_names)\n",
    "print(\"Num. attributes to be used in total:\", D)\n",
    "assert len(attr_names) == len(alt_ids) # length check\n",
    "assert max(alt_ids) + 1 == num_alternatives    \n",
    "\n",
    "resp_ids = np.arange(num_resp)\n",
    "print(\"Num respondents:\", num_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Mixed Logit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary dictionary for Pyro model implementation\n",
    "beta_to_params_map = [param_ids[np.where(alt_ids == i)[0]] for i in range(num_alternatives)]\n",
    "\n",
    "# auxiliary CUDA matrix for Pyro model\n",
    "zeros_vec = torch.zeros(T,num_resp,num_alternatives).cuda()\n",
    "\n",
    "pyro.enable_validation(False)    # <---- This is always a good idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 500\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = num_resp \n",
    "#BATCH_SIZE = 2000 # CHANGED\n",
    "#BATCH_SIZE = int(num_resp / 5)\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "diagonal_alpha = False\n",
    "diagonal_beta_mu = False\n",
    "\n",
    "def model(x, y, alt_av, alt_ids_cuda):\n",
    "    # global parameters in the model\n",
    "    if diagonal_alpha:\n",
    "        alpha_mu = pyro.sample(\"alpha\", dist.Normal(torch.zeros(len(non_mix_params), device=x.device), 1).to_event(1))\n",
    "    else:\n",
    "        alpha_mu = pyro.sample(\"alpha\", dist.MultivariateNormal(torch.zeros(len(non_mix_params), device=x.device), \n",
    "                                            scale_tril=torch.tril(1*torch.eye(len(non_mix_params), device=x.device))))\n",
    "    \n",
    "    if diagonal_beta_mu:\n",
    "        beta_mu = pyro.sample(\"beta_mu\", dist.Normal(torch.zeros(len(mix_params), device=x.device), 1.).to_event(1))\n",
    "    else:\n",
    "        beta_mu = pyro.sample(\"beta_mu\", dist.MultivariateNormal(torch.zeros(len(mix_params), device=x.device), \n",
    "                                            scale_tril=torch.tril(1*torch.eye(len(mix_params), device=x.device))))\n",
    "    \n",
    "    # Vector of variances for each of the d variables\n",
    "    theta = pyro.sample(\"theta\", dist.HalfCauchy(10.*torch.ones(len(mix_params), device=x.device)).to_event(1))\n",
    "    # Lower cholesky factor of a correlation matrix\n",
    "    eta = 1.*torch.ones(1, device=x.device)  # Implies a uniform distribution over correlation matrices\n",
    "    L_omega = pyro.sample(\"L_omega\", dist.LKJCorrCholesky(len(mix_params), eta))\n",
    "    # Lower cholesky factor of the covariance matrix\n",
    "    L_Omega = torch.mm(torch.diag(theta.sqrt()), L_omega)\n",
    "        \n",
    "    # local parameters in the model\n",
    "    random_params = pyro.sample(\"beta_resp\", dist.MultivariateNormal(beta_mu.repeat(num_resp,1), \n",
    "                                                                     scale_tril=L_Omega).to_event(1))\n",
    "    \n",
    "    # vector of respondent parameters: global + local (respondent)\n",
    "    params_resp = torch.cat([alpha_mu.repeat(num_resp,1), random_params], dim=-1)\n",
    "\n",
    "    # vector of betas of MXL (may repeat the same learnable parameter multiple times; random + fixed effects)\n",
    "    beta_resp = torch.cat([params_resp[:,beta_to_params_map[i]] for i in range(num_alternatives)], dim=-1)\n",
    "    \n",
    "    with pyro.plate(\"locals\", len(x), subsample_size=BATCH_SIZE) as ind:\n",
    "        \n",
    "        with pyro.plate(\"data_resp\", T):\n",
    "            # compute utilities for each alternative\n",
    "            utilities = torch.scatter_add(zeros_vec[:,ind,:],\n",
    "                                          2, \n",
    "                                          alt_ids_cuda[ind,:,:].transpose(0,1), \n",
    "                                          torch.mul(x[ind,:,:].transpose(0,1), beta_resp[ind,:]))\n",
    "            \n",
    "            # adjust utility for unavailable alternatives\n",
    "            utilities += alt_av[ind,:,:].transpose(0,1)\n",
    "\n",
    "            # likelihood\n",
    "            pyro.sample(\"obs\", dist.Categorical(logits=utilities), obs=y[ind,:].transpose(0,1))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify variational approximation q (guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softplus\n",
    "\n",
    "def my_local_guide(x, y, alt_av, alt_ids):\n",
    "    if diagonal_alpha:\n",
    "        alpha_loc = pyro.param('alpha_loc', torch.randn(len(non_mix_params), device=x.device))\n",
    "        alpha_scale = pyro.param('alpha_scale', 1.*torch.ones(len(non_mix_params), device=x.device),\n",
    "                                 constraint=constraints.positive)\n",
    "        alpha = pyro.sample(\"alpha\", dist.Normal(alpha_loc, alpha_scale).to_event(1))\n",
    "    else:\n",
    "        alpha_loc = pyro.param('alpha_loc', torch.randn(len(non_mix_params), device=x.device))\n",
    "        alpha_scale = pyro.param(\"alpha_scale\", torch.tril(1.*torch.eye(len(non_mix_params), device=x.device)),\n",
    "                                 constraint=constraints.lower_cholesky)\n",
    "        alpha = pyro.sample(\"alpha\", dist.MultivariateNormal(alpha_loc, scale_tril=alpha_scale))\n",
    "    \n",
    "    if diagonal_beta_mu:\n",
    "        beta_mu_loc = pyro.param('beta_mu_loc', torch.randn(len(mix_params), device=x.device))\n",
    "        beta_mu_scale = pyro.param('beta_mu_scale', 1.*torch.ones(len(mix_params), device=x.device),\n",
    "                                   constraint=constraints.positive)\n",
    "        beta_mu = pyro.sample(\"beta_mu\", dist.Normal(beta_mu_loc, beta_mu_scale).to_event(1))\n",
    "    else:\n",
    "        beta_mu_loc = pyro.param('beta_mu_loc', torch.randn(len(mix_params), device=x.device))\n",
    "        beta_mu_scale = pyro.param(\"beta_mu_scale\", torch.tril(1.*torch.eye(len(mix_params), device=x.device)),\n",
    "                                   constraint=constraints.lower_cholesky)\n",
    "        beta_mu = pyro.sample(\"beta_mu\", dist.MultivariateNormal(beta_mu_loc, scale_tril=beta_mu_scale))\n",
    "    \n",
    "    beta_loc = pyro.param('beta_resp_loc', torch.randn(num_resp, len(mix_params), device=x.device))\n",
    "    beta_scale = pyro.param('beta_resp_scale', torch.tril(1.*torch.eye(len(mix_params), len(mix_params), device=x.device)),\n",
    "                            constraint=constraints.lower_cholesky)\n",
    "    pyro.sample(\"beta_resp\", dist.MultivariateNormal(beta_loc, scale_tril=beta_scale).to_event(1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoGuideList(model)\n",
    "guide.add(AutoDiagonalNormal(poutine.block(model, expose=['theta', 'L_omega'])))\n",
    "guide.add(my_local_guide)  # automatically wrapped in an AutoCallable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for running inference\n",
    "train_x = torch.tensor(alt_attributes, dtype=torch.float)\n",
    "train_x = train_x.cuda()\n",
    "train_y = torch.tensor(true_choices, dtype=torch.int)\n",
    "train_y = train_y.cuda()\n",
    "alt_av_cuda = torch.from_numpy(alt_availability)\n",
    "alt_av_cuda = alt_av_cuda.cuda()\n",
    "alt_av_mat = alt_availability.copy()\n",
    "alt_av_mat[np.where(alt_av_mat == 0)] = -1e9\n",
    "alt_av_mat -= 1\n",
    "alt_av_mat_cuda = torch.from_numpy(alt_av_mat).float()\n",
    "alt_av_mat_cuda = alt_av_mat_cuda.cuda()\n",
    "#alt_ids_cuda = torch.from_numpy(alt_ids[:,np.newaxis].repeat(1*num_resp,1).T.reshape(num_resp,1,-1))\n",
    "alt_ids_cuda = torch.from_numpy(alt_ids[:,np.newaxis].repeat(T*num_resp,1).T.reshape(num_resp,T,-1))\n",
    "alt_ids_cuda = alt_ids_cuda.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace = poutine.trace(model).get_trace(train_x, train_y, alt_av_mat_cuda, alt_ids_cuda)\n",
    "#trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "#print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# function for calculating likelihood and accuracy\n",
    "def loglikelihood(X, y, alt_av, alpha, beta, beta_resps):\n",
    "    # gather vector of params for respondent\n",
    "    params_resp = np.hstack([alpha[:,np.newaxis].repeat(num_resp,1).T, beta_resps])\n",
    "    \n",
    "    # build vector of betas for respondent\n",
    "    beta_resp = np.hstack([params_resp[:,param_ids[np.where(alt_ids == i)[0]]] for i in range(num_alternatives)])\n",
    "    \n",
    "    # calculate utilities based on params\n",
    "    utilities = np.zeros((num_resp, T, J))\n",
    "    for resp_id in range(num_resp):\n",
    "        for i in range(num_alternatives):\n",
    "            utilities[resp_id,:,i] = np.dot(X[resp_id,:,np.where(alt_ids == i)[0]].T, \n",
    "                                            beta_resp[resp_id, np.where(alt_ids == i)[0]]).T\n",
    "\n",
    "    # adjust utility for unavailable alternatives\n",
    "    utilities += alt_av\n",
    "\n",
    "    # likelihood\n",
    "    probs = softmax(utilities, axis=2)\n",
    "    loglik = np.sum(np.log(probs.reshape(num_resp*T,J)[np.arange(num_resp*T), y.flatten()]))\n",
    "    acc = np.mean(np.argmax(probs, axis=2) == y[:,:])\n",
    "    \n",
    "    return loglik, acc\n",
    "\n",
    "def sim_loglikelihood(X, y, alt_av, alpha, beta, betaCovChol, num_samples=1000):\n",
    "    #betaCovChol = np.linalg.cholesky(betaCov)\n",
    "    pSim = np.zeros((num_samples, num_resp))\n",
    "\n",
    "    for i in np.arange(num_samples):\n",
    "        paramRnd = beta + (betaCovChol @ np.random.randn(K, num_resp)).T\n",
    "\n",
    "        # gather vector of params for respondent\n",
    "        params_resp = np.hstack([alpha[:,np.newaxis].repeat(num_resp,1).T, paramRnd])\n",
    "\n",
    "        # build vector of betas for respondent\n",
    "        beta_resp = np.hstack([params_resp[:, param_ids[np.where(alt_ids == i)[0]]] for i in range(num_alternatives)])\n",
    "\n",
    "        for resp_id in range(num_resp):\n",
    "            # calculate utilities based on params\n",
    "            utilities = np.vstack([np.dot(X[resp_id,:,np.where(alt_ids == i)[0]].T, \n",
    "                                          beta_resp[resp_id, np.where(alt_ids == i)[0]]) for i in range(num_alternatives)])\n",
    "\n",
    "            # adjust utility for unavailable alternatives\n",
    "            utilities = utilities.T + alt_av[resp_id]\n",
    "\n",
    "            # likelihood\n",
    "            probs = softmax(utilities, axis=1)\n",
    "            lPInd = np.sum(np.log(probs[np.arange(T), y[resp_id]]))\n",
    "\n",
    "            pSim[i, resp_id] = np.exp(lPInd)\n",
    "\n",
    "    logLik = np.sum(np.log(np.mean(pSim, axis=0)))\n",
    "    \n",
    "    return logLik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_param_args(module_name, param_name):\n",
    "    if '_loc' in param_name:\n",
    "        return {\"lr\": 0.005}\n",
    "    elif '_scale' in param_name:\n",
    "        return {\"lr\": 0.005} # CHANGED\n",
    "    else:\n",
    "        return {\"lr\": 0.005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodr/env36/lib/python3.6/site-packages/pyro/infer/svi.py:50: FutureWarning: The `num_samples` argument to SVI is deprecated and will be removed in a future release. Use `pyro.infer.Predictive` class to draw samples from the posterior.\n",
      "  'samples from the posterior.', FutureWarning)\n",
      "[Epoch 0] Elbo: 6446; Loglik: -4016; Acc.: 0.474; Alpha RMSE: 0.947; Beta RMSE: 1.017; BetaInd RMSE: 1.413\n",
      "[Epoch 100] Elbo: 5582; Loglik: -3460; Acc.: 0.591; Alpha RMSE: 0.633; Beta RMSE: 1.007; BetaInd RMSE: 1.263\n",
      "[Epoch 200] Elbo: 4664; Loglik: -3144; Acc.: 0.593; Alpha RMSE: 0.370; Beta RMSE: 0.933; BetaInd RMSE: 1.186\n",
      "[Epoch 300] Elbo: 3946; Loglik: -2983; Acc.: 0.598; Alpha RMSE: 0.223; Beta RMSE: 0.802; BetaInd RMSE: 1.144\n",
      "[Epoch 400] Elbo: 3844; Loglik: -2900; Acc.: 0.593; Alpha RMSE: 0.105; Beta RMSE: 0.690; BetaInd RMSE: 1.110\n",
      "[Epoch 500] Elbo: 3807; Loglik: -2863; Acc.: 0.604; Alpha RMSE: 0.088; Beta RMSE: 0.614; BetaInd RMSE: 1.068\n",
      "[Epoch 600] Elbo: 3769; Loglik: -2848; Acc.: 0.607; Alpha RMSE: 0.074; Beta RMSE: 0.528; BetaInd RMSE: 1.027\n",
      "[Epoch 700] Elbo: 3691; Loglik: -2844; Acc.: 0.609; Alpha RMSE: 0.075; Beta RMSE: 0.483; BetaInd RMSE: 0.986\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-57e6eb27c96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0melbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt_av_mat_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt_ids_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0melbo_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \"\"\"\n\u001b[1;32m     49\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 50\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mguide_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[1;32m     43\u001b[0m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/nn/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pyro_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/autoguide/guides.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/nn/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pyro_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/infer/autoguide/guides.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiject_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munconstrained_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mlog_density\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_abs_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munconstrained_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mlog_density\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_rightmost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_density\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_density\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mx_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_x_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mx_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/distributions/transforms/cholesky.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vector_to_l_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env36/lib/python3.6/site-packages/pyro/distributions/transforms/cholesky.py\u001b[0m in \u001b[0;36m_vector_to_l_cholesky\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svi = SVI(model,\n",
    "          guide,\n",
    "          optim.ClippedAdam(per_param_args),\n",
    "          loss=Trace_ELBO(),\n",
    "          num_samples=1000)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "num_epochs = 10000\n",
    "elbo_losses = []\n",
    "alpha_errors = []\n",
    "beta_errors = []\n",
    "betaInd_errors = []\n",
    "track_loglik = True\n",
    "best_elbo = np.inf\n",
    "patience_thre = 10\n",
    "patience_count = 0\n",
    "tic = time.time()\n",
    "for j in range(num_epochs):\n",
    "    elbo = svi.step(train_x, train_y, alt_av_mat_cuda, alt_ids_cuda)\n",
    "    elbo_losses += [elbo]\n",
    "    \n",
    "    if j % 100 == 0:\n",
    "        if track_loglik:\n",
    "            alpha_params = pyro.param(\"alpha_loc\").data.cpu().numpy()\n",
    "            beta_params = pyro.param(\"beta_mu_loc\").data.cpu().numpy()\n",
    "            params_resps = pyro.param(\"beta_resp_loc\").data.cpu().numpy()\n",
    "            \n",
    "            alpha_rmse = np.sqrt(np.mean((true_alpha - alpha_params)**2))\n",
    "            beta_rmse = np.sqrt(np.mean((true_beta - beta_params)**2))\n",
    "            params_resps_rmse = np.sqrt(np.mean((betaInd_tmp - params_resps)**2))\n",
    "            alpha_errors += [alpha_rmse]\n",
    "            beta_errors += [beta_rmse]\n",
    "            betaInd_errors += [params_resps_rmse]\n",
    "            \n",
    "            loglik, acc = loglikelihood(alt_attributes, true_choices, alt_av_mat, \n",
    "                                        alpha_params, beta_params, params_resps)\n",
    "            logging.info(\"[Epoch %d] Elbo: %.0f; Loglik: %.0f; Acc.: %.3f; Alpha RMSE: %.3f; Beta RMSE: %.3f; BetaInd RMSE: %.3f\" % (j, \n",
    "                                                                          elbo, loglik, acc, alpha_rmse, beta_rmse, params_resps_rmse))\n",
    "        else:\n",
    "            logging.info(\"Elbo loss: %.2f\" % (elbo,))\n",
    "            \n",
    "        if np.mean(elbo_losses[-1000::10]) < best_elbo:\n",
    "            best_elbo = np.mean(elbo_losses[-1000::10])\n",
    "            patience_count = 0\n",
    "        else:\n",
    "            patience_count += 1\n",
    "            #print(patience_count)\n",
    "            if patience_count >= patience_thre:\n",
    "                logging.info(\"Elbo converged!\")\n",
    "                break\n",
    "            \n",
    "toc = time.time() - tic\n",
    "print(\"Elapsed time:\", toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "alpha_params = pyro.param(\"alpha_loc\").data.cpu().numpy()\n",
    "beta_params = pyro.param(\"beta_mu_loc\").data.cpu().numpy()\n",
    "beta_params_cov = pyro.param(\"beta_mu_scale\").data.cpu().numpy()\n",
    "params_resps = pyro.param(\"beta_resp_loc\").data.cpu().numpy()\n",
    "\n",
    "alpha_error = np.abs(true_alpha - alpha_params).mean()\n",
    "alpha_rmse = np.sqrt(np.mean((true_alpha - alpha_params)**2))\n",
    "beta_error = np.abs(true_beta - beta_params).mean()\n",
    "beta_rmse = np.sqrt(np.mean((true_beta - beta_params)**2))\n",
    "params_resps_error = np.abs(betaInd_tmp - params_resps).mean()\n",
    "params_resps_rmse = np.sqrt(np.mean((betaInd_tmp - params_resps)**2))\n",
    "\n",
    "loglik, acc = loglikelihood(alt_attributes, true_choices, alt_av_mat, \n",
    "                            alpha_params, beta_params, params_resps)\n",
    "\n",
    "loglik_hyp,_ = loglikelihood(alt_attributes, true_choices, alt_av_mat, \n",
    "                             alpha_params, beta_params, np.tile(beta_params, [N,T]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    svi_posterior = svi.run(train_x, train_y, alt_av_mat_cuda, alt_ids_cuda)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_omega_posterior = EmpiricalMarginal(svi, sites=[\"L_omega\"])._get_samples_and_weights()[0]\n",
    "L_omega = L_omega_posterior.mean(axis=0)[0].detach().cpu().numpy()\n",
    "theta_posterior = EmpiricalMarginal(svi, sites=[\"theta\"])._get_samples_and_weights()[0]\n",
    "L_Omega = torch.mm(torch.diag(theta_posterior.mean(axis=0)[0].sqrt()), L_omega_posterior.mean(axis=0)[0])\n",
    "L_Omega = L_Omega.detach().cpu().numpy()\n",
    "\n",
    "Omega_params = np.dot(L_Omega,L_Omega.T)\n",
    "Omega_rmse = np.sqrt(np.mean((true_Omega - Omega_params)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. posterior samples: 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Num. posterior samples:\", L_omega_posterior.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha: [-0.8  0.8  1.2]\n",
      "Estimated alpha: [-0.845  0.725  1.017]\n",
      "Mean error (alpha): 0.10072374741236367\n",
      "RMSE (alpha): 0.1168468747239226\n",
      "\n",
      "True beta: [-0.8  0.8  1.  -0.8  1.5]\n",
      "Estimated beta: [-0.713  0.728  1.083 -0.832  1.593]\n",
      "Mean error (beta): 0.07328916549682618\n",
      "RMSE (beta): 0.07647299422258626\n",
      "\n",
      "True Omega: [[1.  0.8 0.8 0.8 0.8]\n",
      " [0.8 1.  0.8 0.8 0.8]\n",
      " [0.8 0.8 1.  0.8 0.8]\n",
      " [0.8 0.8 0.8 1.  0.8]\n",
      " [0.8 0.8 0.8 0.8 1. ]]\n",
      "Estimated Omega: [[1.236 0.424 0.417 0.851 0.572]\n",
      " [0.424 0.873 0.346 0.574 0.579]\n",
      " [0.417 0.346 0.919 0.632 0.494]\n",
      " [0.851 0.574 0.632 1.478 0.768]\n",
      " [0.572 0.579 0.494 0.768 1.165]]\n",
      "RMSE (Omega): 0.2739967143121211\n",
      "\n",
      "Mean error (params resps): 0.6164754143723057\n",
      "RMSE (params resps): 0.7697693687378329\n",
      "\n",
      "Loglikelihood: -2987.582350630534\n",
      "\n",
      "Loglikelihood (hyper-priors only): -3554.905854191506\n",
      "\n",
      "Loglikelihood (simulated at posterior means): -3497.6674155882556\n"
     ]
    }
   ],
   "source": [
    "print(\"True alpha:\", true_alpha)\n",
    "print(\"Estimated alpha:\", alpha_params)\n",
    "print(\"Mean error (alpha):\", alpha_error)\n",
    "print(\"RMSE (alpha):\", alpha_rmse)\n",
    "print(\"\\nTrue beta:\", true_beta)\n",
    "print(\"Estimated beta:\", beta_params)\n",
    "print(\"Mean error (beta):\", beta_error)\n",
    "print(\"RMSE (beta):\", beta_rmse)\n",
    "print(\"\\nTrue Omega:\", true_Omega)\n",
    "print(\"Estimated Omega:\", Omega_params)\n",
    "print(\"RMSE (Omega):\", Omega_rmse)\n",
    "print(\"\\nMean error (params resps):\", params_resps_error)\n",
    "print(\"RMSE (params resps):\", params_resps_rmse)\n",
    "print(\"\\nLoglikelihood:\", loglik)\n",
    "print(\"\\nLoglikelihood (hyper-priors only):\", loglik_hyp)\n",
    "\n",
    "sim_loglik = sim_loglikelihood(alt_attributes, true_choices, alt_av_mat, \n",
    "                               alpha_params, beta_params, L_Omega, num_samples=200)\n",
    "print(\"\\nLoglikelihood (simulated at posterior means):\", sim_loglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"Results_FakeData_N%d_T%d_J%d_L%d_K%d_Corr%.1f_Scale%.1f_Batch%d\" % (N,T,J,L,K,\n",
    "                                                                                   corr,scale_factor,\n",
    "                                                                                   BATCH_SIZE)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "fname = output_dir + \"/Pyro_LKJ_SVI.txt\"\n",
    "if not os.path.exists(fname):\n",
    "    fw = open(fname, \"w\")\n",
    "    fw.write(\"Run\\tTime\\tLoglik\\tSim. Loglik\\tLoglik (hyper)\\tRMSE alpha\\tRMSE beta\\tRMSE betaInd\\tRMSE Omega\\n\")\n",
    "else:\n",
    "    fw = open(fname, \"a\")\n",
    "    \n",
    "fw.write(\"%d\\t%.0f\\t%.1f\\t%.1f\\t%.1f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\n\" % (RUN, toc, \n",
    "                                                            loglik, sim_loglik, loglik_hyp, \n",
    "                                                            alpha_rmse, beta_rmse, params_resps_rmse, Omega_rmse))\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(fname.replace(\".txt\",\"_Run%d.pickle\" % (RUN,)), 'wb') as f:\n",
    "    pickle.dump({\"elbo_losses\": elbo_losses,\n",
    "                 \"alpha_errors\": alpha_errors,\n",
    "                 \"beta_errors\": beta_errors,\n",
    "                 \"betaInd_errors\": betaInd_errors}, \n",
    "                f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "#from joblib import Parallel, delayed\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import invwishart\n",
    "import scipy.sparse\n",
    "from math import floor\n",
    "import h5py\n",
    "\n",
    "from mxl import corrcov, prepareData, mvnlpdf, probMxl, pPredMxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Mixed Logit Model\n",
    "\n",
    "Generative process:\n",
    "\n",
    "1. Draw fixed taste parameters $\\boldsymbol\\alpha | \\boldsymbol\\lambda_0, \\boldsymbol\\Xi_0 \\sim \\mathcal{N}(\\boldsymbol\\lambda_0, \\boldsymbol\\Xi_0)$\n",
    "\n",
    "<!-- sep -->\n",
    "\n",
    "2. Draw prior mean vector $\\boldsymbol\\zeta | \\boldsymbol\\mu_0, \\boldsymbol\\Sigma_0 \\sim \\mathcal{N}(\\boldsymbol\\mu_0, \\boldsymbol\\Sigma_0)$\n",
    "\n",
    "3. Draw hyper-prior $a_k | A_k \\sim \\mbox{Gamma}\\big(\\frac{1}{2}, \\frac{1}{A_k^2}\\big)$ for $k=1,\\dots,K$\n",
    "\n",
    "4. Draw prior covariance matrix $\\boldsymbol\\Omega | \\nu, \\textbf{a} \\sim \\mbox{IW}\\big(\\nu + K - 1, 2\\nu \\, \\mbox{diag}(\\textbf{a})\\big)$\n",
    "\n",
    "<!-- sep -->\n",
    "\n",
    "5. For each decision-maker $n \\in \\{1,\\dots,N\\}$:\n",
    "\n",
    "    1. Draw random taste parameters $\\boldsymbol\\beta_n | \\boldsymbol\\zeta, \\boldsymbol\\Omega \\sim \\mathcal{N}(\\boldsymbol\\zeta, \\boldsymbol\\Omega)$\n",
    "    \n",
    "    2. For each choice occasion $t \\in \\{1,\\dots,T_n\\}$:\n",
    "    \n",
    "        * Draw observed choice $y_{nt} | \\boldsymbol\\alpha, \\boldsymbol\\beta_n, \\textbf{X}_{nt} \\sim \\mbox{MNL}(\\boldsymbol\\alpha, \\boldsymbol\\beta_n, \\textbf{X}_{nt})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs sampler\n",
    "\n",
    "### Updates\n",
    "\n",
    "Update $\\boldsymbol\\zeta$ by sampling $\\boldsymbol\\zeta \\sim \\mathcal{N}\\Big(\\frac{1}{N} \\sum_{n=1}^N \\boldsymbol\\beta_n, \\frac{\\boldsymbol\\Omega}{N}\\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_zeta(paramRnd, Omega, nRnd, nInd):\n",
    "    zeta = paramRnd.mean(axis = 0) + np.linalg.cholesky(Omega) @ np.random.randn(nRnd,) / np.sqrt(nInd)\n",
    "    return zeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update $\\boldsymbol\\Omega$ by sampling $\\boldsymbol\\Omega \\sim \\mbox{IW}\\Big(\\nu+N+K-1,2\\nu \\, \\mbox{diag}(\\textbf{a}) + \\sum_{n=1}^N (\\boldsymbol\\beta_n-\\boldsymbol\\zeta)(\\boldsymbol\\beta_n-\\boldsymbol\\zeta)^T \\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_Omega(paramRnd, zeta, nu, iwDiagA, diagCov, nRnd, nInd):\n",
    "    betaS = paramRnd - zeta\n",
    "    Omega = np.array(invwishart.rvs(nu + nInd + nRnd - 1, \n",
    "                                    2 * nu * np.diag(iwDiagA) + betaS.T @ betaS)).reshape((nRnd, nRnd))\n",
    "    if diagCov: Omega = np.diag(np.diag(Omega))\n",
    "    return Omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update $a_k$ for all $k \\in \\{1,\\dots,K\\}$ by sampling $a_k \\sim \\mbox{Gamma}\\Big( \\frac{\\nu+K}{2}, \\frac{1}{A_k^2} + \\nu \\, (\\boldsymbol\\Omega^{-1})_{kk} \\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_iwDiagA(Omega, nu, invASq, nRnd):\n",
    "    iwDiagA = np.random.gamma((nu + nRnd) / 2, 1 / (invASq + nu * np.diag(np.linalg.inv(Omega))))\n",
    "    return iwDiagA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update $\\boldsymbol\\beta_n$ for all $n \\in \\{1,\\dots,N\\}$:\n",
    "\n",
    "* Propose $\\tilde{\\boldsymbol\\beta}_n = \\boldsymbol\\beta_n + \\sqrt{\\rho_\\boldsymbol\\beta} \\, \\mbox{chol}(\\boldsymbol\\Omega) \\, \\boldsymbol\\eta$, where $\\boldsymbol\\eta \\sim \\mathcal{N}(\\textbf{0},\\textbf{I}_K)$\n",
    "\n",
    "\n",
    "* Compute $r = \\frac{ P(y_n|\\textbf{X}_n,\\boldsymbol\\alpha,\\tilde{\\boldsymbol\\beta}_n) \\, \\phi(\\tilde{\\boldsymbol\\beta}_n|\\boldsymbol\\zeta,\\boldsymbol\\Omega) }{ P(y_n|\\textbf{X}_n,\\boldsymbol\\alpha,{\\boldsymbol\\beta}_n) \\, \\phi({\\boldsymbol\\beta}_n|\\boldsymbol\\zeta,\\boldsymbol\\Omega) }$\n",
    "\n",
    "\n",
    "* Draw $u \\sim \\mbox{Uniform}(0,1)$. If $r \\leq u$, accept the proposal, else reject it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_paramRnd(\n",
    "        paramFix, paramRnd, zeta, Omega,\n",
    "        lPInd,\n",
    "        xFix, xFix_transBool, xFix_trans, nFix, \n",
    "        xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "        nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs,\n",
    "        rho):\n",
    "    lPhi = mvnlpdf(paramRnd, zeta, Omega)\n",
    "    paramRnd_star = paramRnd + np.sqrt(rho) * (np.linalg.cholesky(Omega) @ np.random.randn(nRnd, nInd)).T    \n",
    "    lPInd_star = probMxl(\n",
    "        paramFix, paramRnd_star,\n",
    "        xFix, xFix_transBool, xFix_trans, nFix, \n",
    "        xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "        nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs)\n",
    "    lPhi_star = mvnlpdf(paramRnd_star, zeta, Omega)\n",
    "\n",
    "    r = np.exp(lPInd_star + lPhi_star - lPInd - lPhi)\n",
    "    idxAccept = np.random.rand(nInd,) <= r\n",
    "\n",
    "    paramRnd[idxAccept, :] = np.array(paramRnd_star[idxAccept, :])\n",
    "    lPInd[idxAccept] = np.array(lPInd_star[idxAccept])\n",
    "\n",
    "    acceptRate = np.mean(idxAccept)\n",
    "    rho = rho - 0.001 * (acceptRate < 0.3) + 0.001 * (acceptRate > 0.3)\n",
    "    return paramRnd, lPInd, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update $\\boldsymbol\\alpha$:\n",
    "\n",
    "* Propose $\\tilde{\\boldsymbol\\alpha} = \\boldsymbol\\alpha + \\sqrt{\\rho_\\boldsymbol\\alpha} \\, \\mbox{chol}(\\boldsymbol\\Xi_0) \\, \\boldsymbol\\eta$, where $\\boldsymbol\\eta \\sim \\mathcal{N}(\\textbf{0},\\textbf{I}_L)$\n",
    "\n",
    "\n",
    "* Compute $r = \\frac{ \\prod_{n=1}^N P(y_n|\\textbf{X}_n,\\tilde{\\boldsymbol\\alpha},{\\boldsymbol\\beta}_n) \\, \\phi(\\tilde{\\boldsymbol\\alpha}|\\boldsymbol\\lambda_0,\\boldsymbol\\Xi_0) }{ \\prod_{n=1}^N P(y_n|\\textbf{X}_n,\\boldsymbol\\alpha,{\\boldsymbol\\beta}_n) \\, \\phi({\\boldsymbol\\alpha}|\\boldsymbol\\lambda_0,\\boldsymbol\\Xi_0) }$\n",
    "\n",
    "\n",
    "* Draw $u \\sim \\mbox{Uniform}(0,1)$. If $r \\leq u$, accept the proposal, else reject it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_paramFix(\n",
    "        paramFix, paramRnd,\n",
    "        lPInd,\n",
    "        xFix, xFix_transBool, xFix_trans, nFix, \n",
    "        xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "        nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs,\n",
    "        rhoF):\n",
    "    paramFix_star = paramFix + np.sqrt(rhoF) * np.random.randn(nFix,)\n",
    "    lPInd_star = probMxl(\n",
    "        paramFix_star, paramRnd,\n",
    "        xFix, xFix_transBool, xFix_trans, nFix, \n",
    "        xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "        nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs)\n",
    "    r = np.exp(np.sum(lPInd_star - lPInd, axis = 0))\n",
    "    if np.random.rand() <= r:\n",
    "        paramFix = np.array(paramFix_star)\n",
    "        lPInd = np.array(lPInd_star)\n",
    "    return paramFix, lPInd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmcChain(\n",
    "        chainID, seed,\n",
    "        mcmc_iter, mcmc_iterBurn, mcmc_iterSampleThin, mcmc_iterMemThin, mcmc_thin, mcmc_disp,\n",
    "        rhoF, rho,\n",
    "        modelName,\n",
    "        paramFix, zeta, Omega, invASq, nu, diagCov,\n",
    "        xFix, xFix_transBool, xFix_trans, nFix, \n",
    "        xRnd, xRnd_transBool, xRnd_trans, nRnd, \n",
    "        nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs):   \n",
    "    \n",
    "    np.random.seed(seed + chainID)\n",
    "    \n",
    "    ###\n",
    "    #Precomputations\n",
    "    ###\n",
    "    \n",
    "    if nRnd > 0:\n",
    "        paramRnd = zeta + (np.linalg.cholesky(Omega) @ np.random.randn(nRnd, nInd)).T\n",
    "        iwDiagA = np.random.gamma(1 / 2, 1 / invASq)\n",
    "    else:\n",
    "        paramRnd = np.zeros((0,0))\n",
    "        iwDiagA = np.zeros((0,0))\n",
    "    \n",
    "    lPInd = probMxl(\n",
    "            paramFix, paramRnd,\n",
    "            xFix, xFix_transBool, xFix_trans, nFix, \n",
    "            xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "            nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs)   \n",
    "    \n",
    "    ###\n",
    "    #Storage\n",
    "    ###\n",
    "    \n",
    "    fileName = modelName + '_draws_chain' + str(chainID + 1) + '.hdf5'\n",
    "    if os.path.exists(fileName):\n",
    "        os.remove(fileName) \n",
    "    file = h5py.File(fileName, \"a\")\n",
    "    \n",
    "    if nFix > 0:\n",
    "        paramFix_store = file.create_dataset('paramFix_store', (mcmc_iterSampleThin, nFix))\n",
    "        \n",
    "        paramFix_store_tmp = np.zeros((mcmc_iterMemThin, nFix))\n",
    "        \n",
    "    if nRnd > 0:\n",
    "        paramRnd_store = file.create_dataset('paramRnd_store', (mcmc_iterSampleThin, nInd, nRnd))\n",
    "        zeta_store = file.create_dataset('zeta_store', (mcmc_iterSampleThin, nRnd))\n",
    "        Omega_store = file.create_dataset('Omega_store', (mcmc_iterSampleThin, nRnd, nRnd))\n",
    "        Corr_store = file.create_dataset('Corr_store', (mcmc_iterSampleThin, nRnd, nRnd))\n",
    "        sd_store = file.create_dataset('sd_store', (mcmc_iterSampleThin, nRnd))\n",
    "        \n",
    "        paramRnd_store_tmp = np.zeros((mcmc_iterMemThin, nInd, nRnd))\n",
    "        zeta_store_tmp = np.zeros((mcmc_iterMemThin, nRnd))\n",
    "        Omega_store_tmp = np.zeros((mcmc_iterMemThin, nRnd, nRnd))\n",
    "        Corr_store_tmp = np.zeros((mcmc_iterMemThin, nRnd, nRnd))\n",
    "        sd_store_tmp = np.zeros((mcmc_iterMemThin, nRnd))\n",
    "    \n",
    "    ###\n",
    "    #Sample\n",
    "    ###\n",
    "    \n",
    "    j = -1\n",
    "    ll = 0\n",
    "    sampleState = 'burn in'\n",
    "    for i in np.arange(mcmc_iter):\n",
    "        if nFix > 0:\n",
    "            paramFix, lPInd = next_paramFix(\n",
    "                    paramFix, paramRnd,\n",
    "                    lPInd,\n",
    "                    xFix, xFix_transBool, xFix_trans, nFix, \n",
    "                    xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "                    nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs,\n",
    "                    rhoF)\n",
    "            \n",
    "        if nRnd > 0:\n",
    "            zeta = next_zeta(paramRnd, Omega, nRnd, nInd)\n",
    "            Omega = next_Omega(paramRnd, zeta, nu, iwDiagA, diagCov, nRnd, nInd)\n",
    "            iwDiagA = next_iwDiagA(Omega, nu, invASq, nRnd)\n",
    "            paramRnd, lPInd, rho = next_paramRnd(\n",
    "                    paramFix, paramRnd, zeta, Omega,\n",
    "                    lPInd,\n",
    "                    xFix, xFix_transBool, xFix_trans, nFix, \n",
    "                    xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "                    nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs,\n",
    "                    rho)\n",
    "        \n",
    "        if ((i + 1) % mcmc_disp) == 0:\n",
    "            if (i + 1) > mcmc_iterBurn:\n",
    "                sampleState = 'sampling'\n",
    "            print('Chain ' + str(chainID + 1) + '; iteration: ' + str(i + 1) + ' (' + sampleState + ')')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        if (i + 1) > mcmc_iterBurn:   \n",
    "            if ((i + 1) % mcmc_thin) == 0:\n",
    "                j+=1\n",
    "            \n",
    "                if nFix > 0:\n",
    "                    paramFix_store_tmp[j,:] = paramFix\n",
    "            \n",
    "                if nRnd > 0:\n",
    "                    paramRnd_store_tmp[j,:,:] = paramRnd\n",
    "                    zeta_store_tmp[j,:] = zeta\n",
    "                    Omega_store_tmp[j,:,:] = Omega\n",
    "                    Corr_store_tmp[j,:,:], sd_store_tmp[j,:,] = corrcov(Omega)\n",
    "                    \n",
    "            if (j + 1) == mcmc_iterMemThin:\n",
    "                l = ll; ll += mcmc_iterMemThin; sl = slice(l, ll)\n",
    "                \n",
    "                print('Storing chain ' + str(chainID + 1))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                if nFix > 0:\n",
    "                    paramFix_store[sl,:] = paramFix_store_tmp\n",
    "                    \n",
    "                if nRnd > 0:\n",
    "                    paramRnd_store[sl,:,:] = paramRnd_store_tmp\n",
    "                    zeta_store[sl,:] = zeta_store_tmp\n",
    "                    Omega_store[sl,:,:] = Omega_store_tmp\n",
    "                    Corr_store[sl,:,:] = Corr_store_tmp\n",
    "                    sd_store[sl,:,] = sd_store_tmp\n",
    "                \n",
    "                j = -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postAna(paramName, nParam, nParam2, mcmc_nChain, mcmc_iterSampleThin, modelName):\n",
    "    colHeaders = ['mean', 'std. dev.', '2.5%', '97.5%', 'Rhat']\n",
    "    q = np.array([0.025, 0.975])\n",
    "    nSplit = 2\n",
    "    \n",
    "    postDraws = np.zeros((mcmc_nChain, mcmc_iterSampleThin, nParam, nParam2))\n",
    "    for c in range(mcmc_nChain):\n",
    "        file = h5py.File(modelName + '_draws_chain' + str(c + 1) + '.hdf5', 'r')\n",
    "        postDraws[c,:,:,:] = np.array(file[paramName + '_store']).reshape((mcmc_iterSampleThin, nParam, nParam2))\n",
    "        \n",
    "    tabPostAna = np.zeros((nParam * nParam2, len(colHeaders)))\n",
    "    postMean = np.mean(postDraws, axis = (0,1))\n",
    "    tabPostAna[:, 0] = np.array(postMean).reshape((nParam * nParam2,))\n",
    "    tabPostAna[:, 1] = np.array(np.std(postDraws, axis = (0,1))).reshape((nParam * nParam2,))\n",
    "    tabPostAna[:, 2] = np.array(np.quantile(postDraws, q[0], axis = (0,1))).reshape((nParam * nParam2,))\n",
    "    tabPostAna[:, 3] = np.array(np.quantile(postDraws, q[1], axis = (0,1))).reshape((nParam * nParam2,))\n",
    "    \n",
    "    m = floor(mcmc_nChain * nSplit)\n",
    "    n = floor(mcmc_iterSampleThin / nSplit)\n",
    "    postDrawsSplit = np.zeros((m, n, nParam, nParam2))\n",
    "    postDrawsSplit[0:mcmc_nChain, :, :, :] = postDraws[:, 0:n, :, :]\n",
    "    postDrawsSplit[mcmc_nChain:m, :, :, :] = postDraws[:,n:mcmc_iterSampleThin, :, :]\n",
    "    muChain = np.mean(postDrawsSplit, axis = 1)\n",
    "    muChainArr = np.array(muChain).reshape((m,1,nParam, nParam2))\n",
    "    mu = np.array(np.mean(muChain, axis = 0)).reshape((1, nParam, nParam2))\n",
    "    B = (n / (m - 1)) * np.sum((muChain - mu)**2)\n",
    "    sSq = (1 / (n - 1)) * np.sum((postDrawsSplit - muChainArr)**2, axis = 1)\n",
    "    W = np.mean(sSq, axis = 0)\n",
    "    varPlus = ((n - 1) / n) * W + B / n\n",
    "    Rhat = np.empty((nParam, nParam2)) * np.nan\n",
    "    W_idx = W > 0\n",
    "    Rhat[W_idx] = np.sqrt(varPlus[W_idx] / W[W_idx])\n",
    "    tabPostAna[:, 4] = np.array(Rhat).reshape((nParam * nParam2,))\n",
    "    \n",
    "    if paramName not in [\"Omega\", \"Corr\", \"paramRnd\"]:\n",
    "        postMean = np.ndarray.flatten(postMean)\n",
    "        \n",
    "    pdTabPostAna = pd.DataFrame(tabPostAna, columns = colHeaders) \n",
    "    return postMean, pdTabPostAna             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(\n",
    "        mcmc_nChain, mcmc_iterBurn, mcmc_iterSample, mcmc_thin, mcmc_iterMem, mcmc_disp, \n",
    "        seed, simDraws,\n",
    "        rhoF, rho,\n",
    "        modelName, deleteDraws,\n",
    "        A, nu, diagCov,\n",
    "        paramFix_inits, zeta_inits, Omega_inits,\n",
    "        indID, obsID, altID, chosen,\n",
    "        xFix, xRnd,\n",
    "        xFix_trans, xRnd_trans):\n",
    "    ###\n",
    "    #Prepare data\n",
    "    ###\n",
    "    \n",
    "    nFix = xFix.shape[1]\n",
    "    nRnd = xRnd.shape[1]\n",
    "    \n",
    "    xFix_transBool = np.sum(xFix_trans) > 0\n",
    "    xRnd_transBool = np.sum(xRnd_trans) > 0  \n",
    "    \n",
    "    xList = [xFix, xRnd]\n",
    "    (xList,\n",
    "     nInd, nObs, nRow,\n",
    "     chosenIdx, nonChosenIdx,\n",
    "     rowsPerInd, rowsPerObs,\n",
    "     map_obs_to_ind, map_avail_to_obs) = prepareData(xList, indID, obsID, chosen)\n",
    "    xFix, xRnd = xList[0], xList[1]\n",
    "    \n",
    "    ### \n",
    "    #Posterior sampling\n",
    "    ###\n",
    "    \n",
    "    mcmc_iter = mcmc_iterBurn + mcmc_iterSample\n",
    "    mcmc_iterSampleThin = floor(mcmc_iterSample / mcmc_thin)\n",
    "    mcmc_iterMemThin = floor(mcmc_iterMem / mcmc_thin)\n",
    "\n",
    "    A = A * np.ones((nRnd,))\n",
    "    invASq = A ** (-2)\n",
    "    \n",
    "    paramFix = paramFix_inits\n",
    "    zeta = zeta_inits\n",
    "    Omega = Omega_inits\n",
    "    \n",
    "    tic = time.time()\n",
    "\n",
    "    for c in range(mcmc_nChain):\n",
    "        mcmcChain(c, seed,\n",
    "                mcmc_iter, mcmc_iterBurn, mcmc_iterSampleThin, mcmc_iterMemThin, mcmc_thin, mcmc_disp,\n",
    "                rhoF, rho,    \n",
    "                modelName,\n",
    "                paramFix, zeta, Omega, invASq, nu, diagCov,\n",
    "                xFix, xFix_transBool, xFix_trans, nFix, \n",
    "                xRnd, xRnd_transBool, xRnd_trans, nRnd, \n",
    "                nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs) \n",
    "    \"\"\"\n",
    "    Parallel(n_jobs = mcmc_nChain)(delayed(mcmcChain)(\n",
    "                c, seed,\n",
    "                mcmc_iter, mcmc_iterBurn, mcmc_iterSampleThin, mcmc_iterMemThin, mcmc_thin, mcmc_disp,\n",
    "                rhoF, rho,    \n",
    "                modelName,\n",
    "                paramFix, zeta, Omega, invASq, nu, diagCov,\n",
    "                xFix, xFix_transBool, xFix_trans, nFix, \n",
    "                xRnd, xRnd_transBool, xRnd_trans, nRnd, \n",
    "                nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs) \n",
    "    for c in range(mcmc_nChain))\n",
    "    \"\"\"\n",
    "\n",
    "    toc = time.time() - tic\n",
    "    \n",
    "    print(' ')\n",
    "    print('Computation time [s]: ' + str(toc))\n",
    "        \n",
    "    ###\n",
    "    #Posterior analysis\n",
    "    ###\n",
    "\n",
    "    if nFix > 0:        \n",
    "        postMean_paramFix, pdTabPostAna_paramFix = postAna('paramFix', nFix, 1, mcmc_nChain, mcmc_iterSampleThin, modelName)\n",
    "        print(' ')\n",
    "        print('Fixed parameters:')    \n",
    "        print(pdTabPostAna_paramFix)\n",
    "    else:\n",
    "        postMean_paramFix = None; pdTabPostAna_paramFix = None;\n",
    " \n",
    "    if nRnd > 0:\n",
    "        postMean_zeta, pdTabPostAna_zeta = postAna('zeta', nRnd, 1, mcmc_nChain, mcmc_iterSampleThin, modelName)\n",
    "        print(' ')\n",
    "        print('Random parameters (means):')    \n",
    "        print(pdTabPostAna_zeta)\n",
    "        \n",
    "        postMean_sd, pdTabPostAna_sd = postAna('sd', nRnd, 1, mcmc_nChain, mcmc_iterSampleThin, modelName)\n",
    "        print(' ')\n",
    "        print('Random parameters (standard deviations):')    \n",
    "        print(pdTabPostAna_sd)\n",
    "        \n",
    "        postMean_Omega, pdTabPostAna_Omega = postAna('Omega', nRnd, nRnd, mcmc_nChain, mcmc_iterSampleThin, modelName)\n",
    "        print(' ')\n",
    "        print('Random parameters (covariance matrix):')    \n",
    "        print(pdTabPostAna_Omega)\n",
    "        \n",
    "        postMean_Corr, pdTabPostAna_Corr = postAna('Corr', nRnd, nRnd, mcmc_nChain, mcmc_iterSampleThin, modelName)\n",
    "        print(' ')\n",
    "        print('Random parameters (correlation matrix):')    \n",
    "        print(pdTabPostAna_Corr)\n",
    "        \n",
    "        postMean_paramRnd, pdTabPostAna_paramRnd = postAna('paramRnd', nInd, nRnd, mcmc_nChain, mcmc_iterSampleThin, modelName)\n",
    "    else:\n",
    "        postMean_zeta = None; pdTabPostAna_zeta = None;\n",
    "        postMean_sd = None; pdTabPostAna_sd = None;\n",
    "        postMean_Omega = None; pdTabPostAna_Omega = None;\n",
    "        postMean_Corr = None; pdTabPostAna_Corr = None;\n",
    "        postMean_paramRnd = None; pdTabPostAna_paramRnd = None;\n",
    "    \n",
    "    ###\n",
    "    #Simulate log-likelihood at posterior means\n",
    "    ###\n",
    "    \n",
    "    if nFix > 0 and nRnd == 0:\n",
    "        simDraws_star = 1\n",
    "    else:\n",
    "        simDraws_star = simDraws\n",
    "    \n",
    "    pSim = np.zeros((simDraws_star, nInd))\n",
    "    \n",
    "    paramFix = 0; paramRnd = 0;\n",
    "    if nFix > 0: paramFix = postMean_paramFix\n",
    "    if nRnd > 0: postMean_chOmega = np.linalg.cholesky(postMean_Omega)      \n",
    "                \n",
    "    for i in np.arange(simDraws_star):\n",
    "        if nRnd > 0:\n",
    "            paramRnd = postMean_zeta + (postMean_chOmega @ np.random.randn(nRnd, nInd)).T\n",
    "            \n",
    "        lPInd = probMxl(\n",
    "                paramFix, paramRnd,\n",
    "                xFix, xFix_transBool, xFix_trans, nFix, \n",
    "                xRnd, xRnd_transBool, xRnd_trans, nRnd,\n",
    "                nInd, rowsPerInd, map_obs_to_ind, map_avail_to_obs)\n",
    "        pSim[i, :] = np.exp(lPInd)\n",
    "    \n",
    "    logLik = np.sum(np.log(np.mean(pSim, axis = 0)))\n",
    "    print(' ')\n",
    "    print('Log-likelihood (simulated at posterior means): ' + str(logLik)) \n",
    "    \n",
    "    ###\n",
    "    #Delete draws\n",
    "    ###\n",
    "    \n",
    "    if deleteDraws:\n",
    "        for c in range(mcmc_nChain):\n",
    "            os.remove(modelName + '_draws_chain' + str(c + 1) + '.hdf5') \n",
    "        \n",
    "    ###\n",
    "    #Save results\n",
    "    ###\n",
    "    \n",
    "    results = {'modelName': modelName, 'seed': seed,\n",
    "               'estimation_time': toc,\n",
    "               'logLik': logLik,\n",
    "               'postMean_paramFix': postMean_paramFix, 'pdTabPostAna_paramFix': pdTabPostAna_paramFix,\n",
    "               'postMean_zeta': postMean_zeta, 'pdTabPostAna_zeta': pdTabPostAna_zeta, \n",
    "               'postMean_sd': postMean_sd, 'pdTabPostAna_sd': pdTabPostAna_sd, \n",
    "               'postMean_Omega': postMean_Omega, 'pdTabPostAna_Omega': pdTabPostAna_Omega, \n",
    "               'postMean_Corr': postMean_Corr, 'pdTabPostAna_Corr': pdTabPostAna_Corr,\n",
    "               'postMean_paramRnd': postMean_paramRnd, 'pdTabPostAna_paramRnd': pdTabPostAna_paramRnd\n",
    "               }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmcChainPred(\n",
    "        chainID, seed,\n",
    "        mcmc_iterSampleThin, mcmc_disp, nTakes, nSim,\n",
    "        modelName,\n",
    "        xFix, nFix, \n",
    "        sim_xRnd, nRnd, \n",
    "        nInd, nObs, nRow,\n",
    "        sim_rowsPerInd, sim_map_avail_to_obs, chosenIdx, nonChosenIdx):   \n",
    "    \n",
    "    np.random.seed(seed + chainID)\n",
    "    \n",
    "    ###\n",
    "    #Retrieve draws\n",
    "    ###\n",
    "    \n",
    "    fileName = modelName + '_draws_chain' + str(chainID + 1) + '.hdf5'\n",
    "    file = h5py.File(fileName, \"r\")\n",
    "    \n",
    "    paramFix_store = None\n",
    "    if nFix: paramFix_store = np.array(file['paramFix_store'])\n",
    "    zeta_store = np.array(file['zeta_store'])\n",
    "    Omega_store = np.array(file['Omega_store'])\n",
    "    \n",
    "    ###\n",
    "    #Simulate\n",
    "    ###\n",
    "\n",
    "    pPred = np.zeros((nRow + nObs,))\n",
    "    vFix = 0 \n",
    "    \n",
    "    for i in np.arange(mcmc_iterSampleThin):\n",
    "        \n",
    "        if nFix: \n",
    "            paramFix = paramFix_store[i,:]\n",
    "            vFix = np.tile(xFix @ paramFix, (nSim,));\n",
    "        \n",
    "        zeta_tmp = zeta_store[i,:]\n",
    "        ch_tmp = np.linalg.cholesky(Omega_store[i,:,:])\n",
    "        \n",
    "        pPred_iter = np.zeros((nRow + nObs,))\n",
    "        \n",
    "        for t in np.arange(nTakes):\n",
    "            paramRnd = zeta_tmp + (ch_tmp @ np.random.randn(nRnd, nInd * nSim)).T\n",
    "            paramRndPerRow = np.repeat(paramRnd, sim_rowsPerInd, axis = 0)\n",
    "            vRnd = np.sum(sim_xRnd * paramRndPerRow, axis = 1)\n",
    "            \n",
    "            pPred_take = pPredMxl(vFix, vRnd, sim_map_avail_to_obs, nSim, chosenIdx, nonChosenIdx)\n",
    "            pPred_iter += pPred_take\n",
    "            \n",
    "        pPred += (pPred_iter / nTakes)\n",
    "        \n",
    "        if ((i + 1) % mcmc_disp) == 0:\n",
    "            print('Chain ' + str(chainID + 1) + '; iteration: ' + str(i + 1) + ' (predictive simulation)')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    pPred /= mcmc_iterSampleThin\n",
    "    return pPred\n",
    "    \n",
    "def predict(\n",
    "        mcmc_nChain, mcmc_iterSample, mcmc_thin, mcmc_disp, nTakes, nSim,\n",
    "        seed,\n",
    "        modelName, deleteDraws,\n",
    "        indID, obsID, altID, chosen,\n",
    "        xFix, xRnd):\n",
    "    ###\n",
    "    #Prepare data\n",
    "    ###\n",
    "    \n",
    "    nFix = xFix.shape[1]\n",
    "    nRnd = xRnd.shape[1]\n",
    "    \n",
    "    xList = [xFix, xRnd]\n",
    "    (xList,\n",
    "     nInd, nObs, nRow,\n",
    "     chosenIdx, nonChosenIdx,\n",
    "     rowsPerInd, rowsPerObs,\n",
    "     _, map_avail_to_obs) = prepareData(xList, indID, obsID, chosen)\n",
    "    xFix, xRnd = xList[0], xList[1]\n",
    "    \n",
    "    sim_xRnd = np.tile(xRnd, (nSim, 1))\n",
    "    sim_rowsPerInd = np.tile(rowsPerInd, (nSim,))\n",
    "    sim_map_avail_to_obs = scipy.sparse.kron(scipy.sparse.eye(nSim), map_avail_to_obs)\n",
    "    \n",
    "    ### \n",
    "    #Predictive simulation\n",
    "    ###\n",
    "    \n",
    "    mcmc_iterSampleThin = floor(mcmc_iterSample / mcmc_thin)\n",
    "    \n",
    "    pPred = np.zeros((nObs + nRow,))\n",
    "    for c in np.arange(mcmc_nChain):\n",
    "        predPred_chain = mcmcChainPred(\n",
    "                c, seed,\n",
    "                mcmc_iterSampleThin, mcmc_disp, nTakes, nSim,\n",
    "                modelName,\n",
    "                xFix, nFix, \n",
    "                sim_xRnd, nRnd, \n",
    "                nInd, nObs, nRow,\n",
    "                sim_rowsPerInd, sim_map_avail_to_obs, chosenIdx, nonChosenIdx)\n",
    "        pPred += predPred_chain\n",
    "    pPred /= mcmc_nChain\n",
    "    \n",
    "    ###\n",
    "    #Delete draws\n",
    "    ###\n",
    "    \n",
    "    if deleteDraws:\n",
    "        for c in range(mcmc_nChain):\n",
    "            os.remove(modelName + '_draws_chain' + str(c + 1) + '.hdf5') \n",
    "\n",
    "    return pPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN number: 1\n",
      "Generating fake data...\n",
      "Error: 46.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#RUN = int(sys.argv[1])\n",
    "RUN = 1\n",
    "print(\"RUN number:\", RUN)\n",
    "\n",
    "np.random.seed(RUN)\n",
    "    \n",
    "\"\"\"\n",
    "###\n",
    "#Load data\n",
    "###\n",
    "\n",
    "data = pd.read_csv('swissmetro_long.csv')\n",
    "data = data[((data['PURPOSE'] != 1) & (data['PURPOSE'] != 3)) != True]\n",
    "data = data[data['ID'] <= 200]\n",
    "\n",
    "###\n",
    "#Prepare data\n",
    "###\n",
    "\n",
    "indID = np.array(data['indID'].values, dtype = 'int64')\n",
    "obsID = np.array(data['obsID'].values, dtype = 'int64')\n",
    "altID = np.array(data['altID'].values, dtype = 'int64')\n",
    "\n",
    "chosen = np.array(data['chosen'].values, dtype = 'int64')\n",
    "\n",
    "tt = np.array(data['TT'].values, dtype = 'float64') / 10\n",
    "cost = np.array(data['CO'].values, dtype = 'float64') / 10\n",
    "he = np.array(data['HE'].values, dtype = 'float64')/ 10\n",
    "ga = np.array(data['GA'].values, dtype = 'int64')\n",
    "cost[(altID <= 2) & (ga == 1)] = 0\n",
    "\n",
    "const2 = 1 * (altID == 2)\n",
    "const3 = 1 * (altID == 3)\n",
    "\"\"\"\n",
    "###\n",
    "#Generate data\n",
    "###\n",
    "\n",
    "N = 500\n",
    "T = 5\n",
    "NT = N * T\n",
    "J = 5\n",
    "NTJ = NT * J\n",
    "\n",
    "L = 3 #no. of fixed paramters\n",
    "K = 5 #no. of random parameters\n",
    "\n",
    "true_alpha = np.array([-0.8, 0.8, 1.2])\n",
    "true_beta = np.array([-0.8, 0.8, 1.0, -0.8, 1.5])\n",
    "true_Omega = np.array([[1.0, 0.8, 0.8, 0.8, 0.8],\n",
    "                       [0.8, 1.0, 0.8, 0.8, 0.8],\n",
    "                       [0.8, 0.8, 1.0, 0.8, 0.8],\n",
    "                       [0.8, 0.8, 0.8, 1.0, 0.8],\n",
    "                       [0.8, 0.8, 0.8, 0.8, 1.0]])\n",
    "# dynamic version\n",
    "corr = 0.8\n",
    "scale_factor = 1.0\n",
    "true_Omega = corr*np.ones((K,K)) # off-diagonal values of cov matrix\n",
    "true_Omega[np.arange(K), np.arange(K)] = 1.0 # diagonal values of cov matrix\n",
    "true_Omega *= scale_factor\n",
    "\n",
    "print(\"Generating fake data...\")\n",
    "xFix = np.random.rand(NTJ, L)\n",
    "xRnd = np.random.rand(NTJ, K)\n",
    "\n",
    "betaInd_tmp = true_beta + \\\n",
    "(np.linalg.cholesky(true_Omega) @ np.random.randn(K, N)).T\n",
    "beta_tmp = np.kron(betaInd_tmp, np.ones((T * J,1)))\n",
    "\n",
    "eps = -np.log(-np.log(np.random.rand(NTJ,)))\n",
    "\n",
    "vDet = xFix @ true_alpha + np.sum(xRnd * beta_tmp, axis = 1)\n",
    "v = vDet + eps\n",
    "\n",
    "vDetMax = np.zeros((NT,))\n",
    "vMax = np.zeros((NT,))\n",
    "\n",
    "chosen = np.zeros((NTJ,), dtype = 'int64')\n",
    "\n",
    "for t in np.arange(NT):\n",
    "    l = t * J; u = (t + 1) * J\n",
    "    altMaxDet = np.argmax(vDet[l:u])\n",
    "    altMax = np.argmax(v[l:u])\n",
    "    vDetMax[t] = altMaxDet\n",
    "    vMax[t] = altMax\n",
    "    chosen[l + altMax] = 1\n",
    "\n",
    "error = np.sum(vMax == vDetMax) / NT * 100\n",
    "print(\"Error:\", error)\n",
    "\n",
    "indID = np.repeat(np.arange(N), T * J)\n",
    "obsID = np.repeat(np.arange(NT), J)\n",
    "altID = np.tile(np.arange(J), NT)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 1; iteration: 1000 (burn in)\n",
      "Chain 1; iteration: 2000 (burn in)\n",
      "Chain 1; iteration: 3000 (burn in)\n",
      "Chain 1; iteration: 4000 (burn in)\n",
      "Chain 1; iteration: 5000 (burn in)\n",
      "Chain 1; iteration: 6000 (burn in)\n",
      "Chain 1; iteration: 7000 (burn in)\n",
      "Chain 1; iteration: 8000 (burn in)\n",
      "Chain 1; iteration: 9000 (burn in)\n",
      "Chain 1; iteration: 10000 (burn in)\n",
      "Chain 1; iteration: 11000 (burn in)\n",
      "Chain 1; iteration: 12000 (burn in)\n",
      "Chain 1; iteration: 13000 (burn in)\n",
      "Chain 1; iteration: 14000 (burn in)\n",
      "Chain 1; iteration: 15000 (burn in)\n",
      "Chain 1; iteration: 16000 (burn in)\n",
      "Chain 1; iteration: 17000 (burn in)\n",
      "Chain 1; iteration: 18000 (burn in)\n",
      "Chain 1; iteration: 19000 (burn in)\n",
      "Chain 1; iteration: 20000 (burn in)\n",
      "Chain 1; iteration: 21000 (sampling)\n",
      "Chain 1; iteration: 22000 (sampling)\n",
      "Chain 1; iteration: 23000 (sampling)\n",
      "Chain 1; iteration: 24000 (sampling)\n",
      "Chain 1; iteration: 25000 (sampling)\n",
      "Chain 1; iteration: 26000 (sampling)\n",
      "Chain 1; iteration: 27000 (sampling)\n",
      "Chain 1; iteration: 28000 (sampling)\n",
      "Chain 1; iteration: 29000 (sampling)\n",
      "Chain 1; iteration: 30000 (sampling)\n",
      "Chain 1; iteration: 31000 (sampling)\n",
      "Chain 1; iteration: 32000 (sampling)\n",
      "Chain 1; iteration: 33000 (sampling)\n",
      "Chain 1; iteration: 34000 (sampling)\n",
      "Chain 1; iteration: 35000 (sampling)\n",
      "Chain 1; iteration: 36000 (sampling)\n",
      "Chain 1; iteration: 37000 (sampling)\n",
      "Chain 1; iteration: 38000 (sampling)\n",
      "Chain 1; iteration: 39000 (sampling)\n",
      "Chain 1; iteration: 40000 (sampling)\n",
      "Storing chain 1\n",
      "Chain 2; iteration: 1000 (burn in)\n",
      "Chain 2; iteration: 2000 (burn in)\n",
      "Chain 2; iteration: 3000 (burn in)\n",
      "Chain 2; iteration: 4000 (burn in)\n",
      "Chain 2; iteration: 5000 (burn in)\n",
      "Chain 2; iteration: 6000 (burn in)\n",
      "Chain 2; iteration: 7000 (burn in)\n",
      "Chain 2; iteration: 8000 (burn in)\n",
      "Chain 2; iteration: 9000 (burn in)\n",
      "Chain 2; iteration: 10000 (burn in)\n",
      "Chain 2; iteration: 11000 (burn in)\n",
      "Chain 2; iteration: 12000 (burn in)\n",
      "Chain 2; iteration: 13000 (burn in)\n",
      "Chain 2; iteration: 14000 (burn in)\n",
      "Chain 2; iteration: 15000 (burn in)\n",
      "Chain 2; iteration: 16000 (burn in)\n",
      "Chain 2; iteration: 17000 (burn in)\n",
      "Chain 2; iteration: 18000 (burn in)\n",
      "Chain 2; iteration: 19000 (burn in)\n",
      "Chain 2; iteration: 20000 (burn in)\n",
      "Chain 2; iteration: 21000 (sampling)\n",
      "Chain 2; iteration: 22000 (sampling)\n",
      "Chain 2; iteration: 23000 (sampling)\n",
      "Chain 2; iteration: 24000 (sampling)\n",
      "Chain 2; iteration: 25000 (sampling)\n",
      "Chain 2; iteration: 26000 (sampling)\n",
      "Chain 2; iteration: 27000 (sampling)\n",
      "Chain 2; iteration: 28000 (sampling)\n",
      "Chain 2; iteration: 29000 (sampling)\n",
      "Chain 2; iteration: 30000 (sampling)\n",
      "Chain 2; iteration: 31000 (sampling)\n",
      "Chain 2; iteration: 32000 (sampling)\n",
      "Chain 2; iteration: 33000 (sampling)\n",
      "Chain 2; iteration: 34000 (sampling)\n",
      "Chain 2; iteration: 35000 (sampling)\n",
      "Chain 2; iteration: 36000 (sampling)\n",
      "Chain 2; iteration: 37000 (sampling)\n",
      "Chain 2; iteration: 38000 (sampling)\n",
      "Chain 2; iteration: 39000 (sampling)\n",
      "Chain 2; iteration: 40000 (sampling)\n",
      "Storing chain 2\n",
      " \n",
      "Computation time [s]: 216.8212149143219\n",
      " \n",
      "Fixed parameters:\n",
      "       mean  std. dev.      2.5%     97.5%      Rhat\n",
      "0 -0.837267   0.089009 -1.014856 -0.663840  1.002694\n",
      "1  0.721469   0.087148  0.551256  0.893252  1.002822\n",
      "2  1.040267   0.088078  0.867975  1.209816  1.002761\n",
      " \n",
      "Random parameters (means):\n",
      "       mean  std. dev.      2.5%     97.5%      Rhat\n",
      "0 -0.671264   0.098509 -0.866385 -0.485153  1.097939\n",
      "1  0.726094   0.101083  0.525080  0.924538  1.093143\n",
      "2  1.083027   0.095154  0.899872  1.277961  1.104998\n",
      "3 -0.804011   0.106232 -1.011829 -0.601886  1.083264\n",
      "4  1.596323   0.106084  1.376662  1.801952  1.088854\n",
      " \n",
      "Random parameters (standard deviations):\n",
      "       mean  std. dev.      2.5%     97.5%      Rhat\n",
      "0  1.068775   0.133633  0.816671  1.337679  1.302195\n",
      "1  0.838697   0.134794  0.593966  1.117340  1.327271\n",
      "2  0.904285   0.149003  0.617777  1.195174  1.283319\n",
      "3  1.158156   0.151751  0.865619  1.451660  1.254413\n",
      "4  0.972916   0.139554  0.680267  1.254003  1.296332\n",
      " \n",
      "Random parameters (covariance matrix):\n",
      "        mean  std. dev.      2.5%     97.5%      Rhat\n",
      "0   1.160137   0.287977  0.666952  1.789386  1.509021\n",
      "1   0.605561   0.186161  0.244499  0.988932  2.051812\n",
      "2   0.623020   0.201012  0.244270  1.045664  1.898192\n",
      "3   0.956747   0.219794  0.549564  1.406089  1.789810\n",
      "4   0.733564   0.203604  0.362392  1.151784  1.938857\n",
      "5   0.605561   0.186161  0.244499  0.988932  2.051812\n",
      "6   0.721582   0.232317  0.352795  1.248450  1.781917\n",
      "7   0.505697   0.171731  0.213385  0.877053  2.224344\n",
      "8   0.754546   0.194269  0.398310  1.164887  1.973381\n",
      "9   0.653920   0.172758  0.366909  1.030702  2.140598\n",
      "10  0.623020   0.201012  0.244270  1.045664  1.898192\n",
      "11  0.505697   0.171731  0.213385  0.877053  2.224344\n",
      "12  0.839933   0.271305  0.381648  1.428441  1.630711\n",
      "13  0.805375   0.215681  0.407207  1.245697  1.869852\n",
      "14  0.639512   0.191845  0.273608  1.028510  1.988467\n",
      "15  0.956747   0.219794  0.549564  1.406089  1.789810\n",
      "16  0.754546   0.194269  0.398310  1.164887  1.973381\n",
      "17  0.805375   0.215681  0.407207  1.245697  1.869852\n",
      "18  1.364354   0.352721  0.749296  2.107317  1.378838\n",
      "19  0.909823   0.202818  0.554481  1.352632  1.908384\n",
      "20  0.733564   0.203604  0.362392  1.151784  1.938857\n",
      "21  0.653920   0.172758  0.366909  1.030702  2.140598\n",
      "22  0.639512   0.191845  0.273608  1.028510  1.988467\n",
      "23  0.909823   0.202818  0.554481  1.352632  1.908384\n",
      "24  0.966040   0.272547  0.462763  1.572524  1.587113\n",
      " \n",
      "Random parameters (correlation matrix):\n",
      "        mean  std. dev.      2.5%     97.5%      Rhat\n",
      "0   1.000000   0.000000  1.000000  1.000000       NaN\n",
      "1   0.683703   0.177303  0.274431  0.930633  2.168249\n",
      "2   0.644916   0.157704  0.289860  0.891164  2.160050\n",
      "3   0.776365   0.128039  0.483510  0.969171  2.889018\n",
      "4   0.711458   0.161678  0.359670  0.949743  2.243110\n",
      "5   0.683703   0.177303  0.274431  0.930633  2.168249\n",
      "6   1.000000   0.000000  1.000000  1.000000       NaN\n",
      "7   0.669423   0.168216  0.302642  0.932811  2.276738\n",
      "8   0.780288   0.135036  0.454093  0.954431  2.613241\n",
      "9   0.799583   0.101572  0.564855  0.959009  3.268075\n",
      "10  0.644916   0.157704  0.289860  0.891164  2.160050\n",
      "11  0.669423   0.168216  0.302642  0.932811  2.276738\n",
      "12  1.000000   0.000000  1.000000  1.000000       NaN\n",
      "13  0.770696   0.130478  0.433524  0.941739  2.623514\n",
      "14  0.728841   0.154896  0.358478  0.931472  2.298721\n",
      "15  0.776365   0.128039  0.483510  0.969171  2.889018\n",
      "16  0.780288   0.135036  0.454093  0.954431  2.613241\n",
      "17  0.770696   0.130478  0.433524  0.941739  2.623514\n",
      "18  1.000000   0.000000  1.000000  1.000000       NaN\n",
      "19  0.810590   0.106996  0.555310  0.963086  3.058084\n",
      "20  0.711458   0.161678  0.359670  0.949743  2.243110\n",
      "21  0.799583   0.101572  0.564855  0.959009  3.268075\n",
      "22  0.728841   0.154896  0.358478  0.931472  2.298721\n",
      "23  0.810590   0.106996  0.555310  0.963086  3.058084\n",
      "24  1.000000   0.000000  1.000000  1.000000       NaN\n",
      " \n",
      "Log-likelihood (simulated at posterior means): -3489.892463148743\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#Estimate MXL via MCMC\n",
    "###\n",
    "\n",
    "#xFix = np.stack((const2, const3), axis = 1)\n",
    "#xRnd = -np.stack((cost, tt), axis = 1) #np.zeros((0,0)) #-np.hstack((cost, he, tt))\n",
    "\n",
    "#Fixed parameter distributions\n",
    "#0: normal\n",
    "#1: log-normal (to assure that fixed parameter is striclty negative or positive)\n",
    "xFix_trans = np.array([0, 0, 0, 0])\n",
    "\n",
    "#Random parameter distributions\n",
    "#0: normal\n",
    "#1: log-normal\n",
    "#2: S_B\n",
    "xRnd_trans = np.array([0, 0])\n",
    "\n",
    "paramFix_inits = np.zeros((xFix.shape[1],))\n",
    "zeta_inits = np.zeros((xRnd.shape[1],))\n",
    "Omega_inits = 0.1 * np.eye(xRnd.shape[1])\n",
    "\n",
    "A = 1.04\n",
    "nu = 2\n",
    "diagCov = False\n",
    "\n",
    "mcmc_nChain = 2\n",
    "mcmc_iterBurn = 20000\n",
    "mcmc_iterSample = 20000\n",
    "mcmc_thin = 5\n",
    "mcmc_iterMem = 20000\n",
    "mcmc_disp = 1000\n",
    "seed = RUN\n",
    "simDraws = 1000    \n",
    "\n",
    "rho = 0.1\n",
    "rhoF = 0.01\n",
    "\n",
    "modelName = 'test'\n",
    "deleteDraws = False\n",
    "\n",
    "results = estimate(\n",
    "        mcmc_nChain, mcmc_iterBurn, mcmc_iterSample, mcmc_thin, mcmc_iterMem, mcmc_disp, \n",
    "        seed, simDraws,\n",
    "        rhoF, rho,\n",
    "        modelName, deleteDraws,\n",
    "        A, nu, diagCov,\n",
    "        paramFix_inits, zeta_inits, Omega_inits,\n",
    "        indID, obsID, altID, chosen,\n",
    "        xFix, xRnd,\n",
    "        xFix_trans, xRnd_trans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results for comparison with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert long format to wide format\n",
    "xs = []\n",
    "ys = []\n",
    "num_resp = N\n",
    "num_alternatives = J\n",
    "for ind in range(num_resp):\n",
    "    #print(\"------------------ individual:\", ind)\n",
    "    ind_ix = np.where(indID == ind)[0]\n",
    "    #print(\"ind_ix:\", ind_ix)\n",
    "    ind_xs = []\n",
    "    ind_ys = []\n",
    "    for n in np.unique(obsID[ind_ix]):\n",
    "        #print(\"--------- observation:\", n)\n",
    "        obs_ix = np.where(obsID == n)[0]\n",
    "        #print(\"obs_ix:\", obs_ix)\n",
    "        \n",
    "        # get attributes (x)\n",
    "        x = [[] for i in range(num_alternatives)]\n",
    "        #print(\"altID:\", altID[obs_ix])\n",
    "        for alt in range(num_alternatives):\n",
    "            if alt in altID[obs_ix]:\n",
    "                x[alt].append(np.hstack([xFix[obs_ix][alt], xRnd[obs_ix][alt]]))\n",
    "            else:\n",
    "                x[alt].append(np.zeros(L+K))\n",
    "        x = np.hstack(x)[0]\n",
    "        #print(\"x:\", x)\n",
    "        ind_xs.append(x)\n",
    "        \n",
    "        # get choice (y)\n",
    "        y = np.argmax(chosen[obs_ix])\n",
    "        #print(\"y:\", y)\n",
    "        ind_ys.append(y)\n",
    "    \n",
    "    xs.append(np.array(ind_xs))\n",
    "    ys.append(np.array(ind_ys))\n",
    "\n",
    "alt_availability = np.ones((N,T,J))\n",
    "alt_attributes = np.array(xs)\n",
    "true_choices = np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. observations: 12500\n",
      "Num. alternatives: 5\n",
      "Parameter IDs to be treated in a Mixed Logit way: [3 4 5 6 7]\n",
      "Parameter IDs to be treated in a MNL way: [0 1 2]\n",
      "Utility functions:\n",
      "\tV_ALT1_n = beta0 * ALT1_XF1 + beta1 * ALT1_XF2 + beta2 * ALT1_XF3 + beta3_n * ALT1_XR1 + beta4_n * ALT1_XR2 + beta5_n * ALT1_XR3 + beta6_n * ALT1_XR4 + beta7_n * ALT1_XR5\n",
      "\tV_ALT2_n = beta0 * ALT2_XF1 + beta1 * ALT2_XF2 + beta2 * ALT2_XF3 + beta3_n * ALT2_XR1 + beta4_n * ALT2_XR2 + beta5_n * ALT2_XR3 + beta6_n * ALT2_XR4 + beta7_n * ALT2_XR5\n",
      "\tV_ALT3_n = beta0 * ALT3_XF1 + beta1 * ALT3_XF2 + beta2 * ALT3_XF3 + beta3_n * ALT3_XR1 + beta4_n * ALT3_XR2 + beta5_n * ALT3_XR3 + beta6_n * ALT3_XR4 + beta7_n * ALT3_XR5\n",
      "\tV_ALT4_n = beta0 * ALT4_XF1 + beta1 * ALT4_XF2 + beta2 * ALT4_XF3 + beta3_n * ALT4_XR1 + beta4_n * ALT4_XR2 + beta5_n * ALT4_XR3 + beta6_n * ALT4_XR4 + beta7_n * ALT4_XR5\n",
      "\tV_ALT5_n = beta0 * ALT5_XF1 + beta1 * ALT5_XF2 + beta2 * ALT5_XF3 + beta3_n * ALT5_XR1 + beta4_n * ALT5_XR2 + beta5_n * ALT5_XR3 + beta6_n * ALT5_XR4 + beta7_n * ALT5_XR5\n",
      "Num. parameters to be estimated: 8\n",
      "Num. attributes to be used in total: 40\n",
      "Num respondents: 500\n"
     ]
    }
   ],
   "source": [
    "# DCM specification\n",
    "num_obs = len(chosen)\n",
    "print(\"Num. observations:\", num_obs)\n",
    "\n",
    "alt_names = [\"ALT1\", \"ALT2\", \"ALT3\", \"ALT4\", \"ALT5\"]\n",
    "assert num_alternatives == len(alt_names)\n",
    "print(\"Num. alternatives:\", num_alternatives)\n",
    "\n",
    "attr_names = ['ALT1_XF1', 'ALT1_XF2','ALT1_XF3', 'ALT1_XR1', 'ALT1_XR2','ALT1_XR3', 'ALT1_XR4', 'ALT1_XR5', \n",
    "              'ALT2_XF1', 'ALT2_XF2','ALT2_XF3', 'ALT2_XR1', 'ALT2_XR2','ALT2_XR3', 'ALT2_XR4', 'ALT2_XR5', \n",
    "              'ALT3_XF1', 'ALT3_XF2','ALT3_XF3', 'ALT3_XR1', 'ALT3_XR2','ALT3_XR3', 'ALT3_XR4', 'ALT3_XR5', \n",
    "              'ALT4_XF1', 'ALT4_XF2','ALT4_XF3', 'ALT4_XR1', 'ALT4_XR2','ALT4_XR3', 'ALT4_XR4', 'ALT4_XR5', \n",
    "              'ALT5_XF1', 'ALT5_XF2','ALT5_XF3', 'ALT5_XR1', 'ALT5_XR2','ALT5_XR3', 'ALT5_XR4', 'ALT5_XR5', ] \n",
    "alt_ids = np.array([0,0,0,0,0,0,0,0,\n",
    "                    1,1,1,1,1,1,1,1,\n",
    "                    2,2,2,2,2,2,2,2,\n",
    "                    3,3,3,3,3,3,3,3,\n",
    "                    4,4,4,4,4,4,4,4]) # assigns attributes to IDs corresponding to alternatives\n",
    "param_ids = np.array([0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7,\n",
    "                      0,1,2,3,4,5,6,7]) # assigns attributes to IDs indicating parameters to be estimated\n",
    "mix_params = np.array([3,4,5,6,7]) # IDs of parameters to be treated with a Mixed Logit formulation\n",
    "non_mix_params = np.array([x for x in range(max(param_ids)+1) if x not in mix_params])\n",
    "print(\"Parameter IDs to be treated in a Mixed Logit way:\", mix_params)\n",
    "print(\"Parameter IDs to be treated in a MNL way:\", non_mix_params)\n",
    "\n",
    "# debug utility functions specified\n",
    "print(\"Utility functions:\")\n",
    "for i in range(num_alternatives):\n",
    "    v_ix = np.where(alt_ids == i)[0]\n",
    "    if param_ids[v_ix[0]] in mix_params:\n",
    "        s = \"\\tV_%s_n = beta%d_n * %s\" % (alt_names[i], param_ids[v_ix[0]], attr_names[v_ix[0]])\n",
    "    else:\n",
    "        s = \"\\tV_%s_n = beta%d * %s\" % (alt_names[i], param_ids[v_ix[0]], attr_names[v_ix[0]])\n",
    "    for j in range(1,len(v_ix)):\n",
    "        if param_ids[v_ix[j]] in mix_params:\n",
    "            s += \" + beta%d_n * %s\" % (param_ids[v_ix[j]], attr_names[v_ix[j]])\n",
    "        else:\n",
    "            s += \" + beta%d * %s\" % (param_ids[v_ix[j]], attr_names[v_ix[j]])\n",
    "    print(s)\n",
    "\n",
    "# further checks and definitions\n",
    "assert len(np.unique(param_ids)) == max(param_ids)+1\n",
    "assert min(param_ids) == 0\n",
    "num_params = max(param_ids) + 1\n",
    "print(\"Num. parameters to be estimated:\", num_params)\n",
    "D = len(attr_names)\n",
    "print(\"Num. attributes to be used in total:\", D)\n",
    "assert len(attr_names) == len(alt_ids) # length check\n",
    "assert max(alt_ids) + 1 == num_alternatives    \n",
    "\n",
    "resp_ids = np.arange(num_resp)\n",
    "print(\"Num respondents:\", num_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# function for calculating likelihood and accuracy\n",
    "def loglikelihood(X, y, alt_av, alpha, beta, beta_resps):\n",
    "    # gather vector of params for respondent\n",
    "    params_resp = np.hstack([alpha[:,np.newaxis].repeat(num_resp,1).T, beta_resps])\n",
    "    \n",
    "    # build vector of betas for respondent\n",
    "    beta_resp = np.hstack([params_resp[:,param_ids[np.where(alt_ids == i)[0]]] for i in range(num_alternatives)])\n",
    "    \n",
    "    # calculate utilities based on params\n",
    "    utilities = np.zeros((num_resp, T, J))\n",
    "    for resp_id in range(num_resp):\n",
    "        for i in range(num_alternatives):\n",
    "            utilities[resp_id,:,i] = np.dot(X[resp_id,:,np.where(alt_ids == i)[0]].T, \n",
    "                                            beta_resp[resp_id, np.where(alt_ids == i)[0]]).T\n",
    "\n",
    "    # adjust utility for unavailable alternatives\n",
    "    utilities += alt_av\n",
    "\n",
    "    # likelihood\n",
    "    probs = softmax(utilities, axis=2)\n",
    "    loglik = np.sum(np.log(probs.reshape(num_resp*T,J)[np.arange(num_resp*T), y.flatten()]))\n",
    "    acc = np.mean(np.argmax(probs, axis=2) == y[:,:])\n",
    "    \n",
    "    return loglik, acc\n",
    "\n",
    "def sim_loglikelihood(X, y, alt_av, alpha, beta, betaCovChol, num_samples=1000):\n",
    "    #betaCovChol = np.linalg.cholesky(betaCov)\n",
    "    pSim = np.zeros((num_samples, num_resp))\n",
    "\n",
    "    for i in np.arange(num_samples):\n",
    "        paramRnd = beta + (betaCovChol @ np.random.randn(K, num_resp)).T\n",
    "\n",
    "        # gather vector of params for respondent\n",
    "        params_resp = np.hstack([alpha[:,np.newaxis].repeat(num_resp,1).T, paramRnd])\n",
    "\n",
    "        # build vector of betas for respondent\n",
    "        beta_resp = np.hstack([params_resp[:, param_ids[np.where(alt_ids == i)[0]]] for i in range(num_alternatives)])\n",
    "        #print(beta_resp.shape)\n",
    "\n",
    "        for resp_id in range(num_resp):\n",
    "            # calculate utilities based on params\n",
    "            utilities = np.vstack([np.dot(X[resp_id,:,np.where(alt_ids == i)[0]].T, \n",
    "                                          beta_resp[resp_id, np.where(alt_ids == i)[0]]) for i in range(num_alternatives)])\n",
    "\n",
    "            # adjust utility for unavailable alternatives\n",
    "            utilities = utilities.T + alt_av[resp_id]\n",
    "            #print(utilities.shape)\n",
    "\n",
    "            # likelihood\n",
    "            probs = softmax(utilities, axis=1)\n",
    "            lPInd = np.sum(np.log(probs[np.arange(T), y[resp_id]]))\n",
    "\n",
    "            pSim[i, resp_id] = np.exp(lPInd)\n",
    "\n",
    "    logLik = np.sum(np.log(np.mean(pSim, axis=0)))\n",
    "    \n",
    "    return logLik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha: [-0.8  0.8  1.2]\n",
      "Estimated alpha: [-0.837  0.721  1.04 ]\n",
      "Mean error (alpha): 0.09184358844781915\n",
      "RMSE (alpha): 0.10499301342436475\n",
      "\n",
      "True beta: [-0.8  0.8  1.  -0.8  1.5]\n",
      "Estimated beta: [-0.671  0.726  1.083 -0.804  1.596]\n",
      "Mean error (beta): 0.07720066158920527\n",
      "RMSE (beta): 0.08743316549301826\n",
      "\n",
      "True Omega: [[1.  0.8 0.8 0.8 0.8]\n",
      " [0.8 1.  0.8 0.8 0.8]\n",
      " [0.8 0.8 1.  0.8 0.8]\n",
      " [0.8 0.8 0.8 1.  0.8]\n",
      " [0.8 0.8 0.8 0.8 1. ]]\n",
      "Estimated Omega: [[1.16  0.606 0.623 0.957 0.734]\n",
      " [0.606 0.722 0.506 0.755 0.654]\n",
      " [0.623 0.506 0.84  0.805 0.64 ]\n",
      " [0.957 0.755 0.805 1.364 0.91 ]\n",
      " [0.734 0.654 0.64  0.91  0.966]]\n",
      "RMSE (Omega): 0.17374069045022084\n",
      "\n",
      "Mean error (params resps): 0.6053718013365736\n",
      "RMSE (params resps): 0.7560506206009248\n",
      "\n",
      "Loglikelihood: -3080.139988713915\n",
      "\n",
      "Loglikelihood (hyper-priors only): -3554.7388359503675\n",
      "\n",
      "Loglikelihood (simulated at posterior means): -3490.3801825040655\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "alpha_params = results[\"postMean_paramFix\"]\n",
    "beta_params = results[\"postMean_zeta\"]\n",
    "params_resps = results[\"postMean_paramRnd\"]\n",
    "Omega_params = results[\"postMean_Omega\"]\n",
    "            \n",
    "alpha_error = np.abs(true_alpha - alpha_params).mean()\n",
    "alpha_rmse = np.sqrt(np.mean((true_alpha - alpha_params)**2))\n",
    "beta_error = np.abs(true_beta - beta_params).mean()\n",
    "beta_rmse = np.sqrt(np.mean((true_beta - beta_params)**2))\n",
    "params_resps_error = np.abs(betaInd_tmp - params_resps).mean()\n",
    "params_resps_rmse = np.sqrt(np.mean((betaInd_tmp - params_resps)**2))\n",
    "Omega_rmse = np.sqrt(np.mean((true_Omega - Omega_params)**2))\n",
    "\n",
    "print(\"True alpha:\", true_alpha)\n",
    "print(\"Estimated alpha:\", alpha_params)\n",
    "print(\"Mean error (alpha):\", alpha_error)\n",
    "print(\"RMSE (alpha):\", alpha_rmse)\n",
    "print(\"\\nTrue beta:\", true_beta)\n",
    "print(\"Estimated beta:\", beta_params)\n",
    "print(\"Mean error (beta):\", beta_error)\n",
    "print(\"RMSE (beta):\", beta_rmse)\n",
    "print(\"\\nTrue Omega:\", true_Omega)\n",
    "print(\"Estimated Omega:\", Omega_params)\n",
    "print(\"RMSE (Omega):\", Omega_rmse)\n",
    "print(\"\\nMean error (params resps):\", params_resps_error)\n",
    "print(\"RMSE (params resps):\", params_resps_rmse)\n",
    "\n",
    "loglik, acc = loglikelihood(alt_attributes, true_choices, np.zeros((N,T,J)), \n",
    "                            alpha_params, beta_params, params_resps)\n",
    "print(\"\\nLoglikelihood:\", loglik)\n",
    "\n",
    "loglik_hyp,_ = loglikelihood(alt_attributes, true_choices, np.zeros((N,T,J)), \n",
    "                             alpha_params, beta_params, np.tile(beta_params, [N,T]))\n",
    "print(\"\\nLoglikelihood (hyper-priors only):\", loglik_hyp)\n",
    "\n",
    "sim_loglik = sim_loglikelihood(alt_attributes, true_choices, np.zeros((N,T,J)), \n",
    "                               results[\"postMean_paramFix\"], results[\"postMean_zeta\"], \n",
    "                               np.linalg.cholesky(results[\"postMean_Omega\"]))\n",
    "print(\"\\nLoglikelihood (simulated at posterior means):\", sim_loglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = num_resp\n",
    "output_dir = \"Results_FakeData_N%d_T%d_J%d_L%d_K%d_Corr%.1f_Scale%.1f_Batch%d\" % (N,T,J,L,K,\n",
    "                                                                                   corr,scale_factor,\n",
    "                                                                                   BATCH_SIZE)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "fname = output_dir + \"/Gibbs.txt\"\n",
    "if not os.path.exists(fname):\n",
    "    fw = open(fname, \"w\")\n",
    "    fw.write(\"Run\\tTime\\tLoglik\\tSim. Loglik\\tLoglik (hyper)\\tRMSE alpha\\tRMSE beta\\tRMSE betaInd\\tRMSE Omega\\n\")\n",
    "else:\n",
    "    fw = open(fname, \"a\")\n",
    "    \n",
    "fw.write(\"%d\\t%.0f\\t%.1f\\t%.1f\\t%.1f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\n\" % (RUN, results[\"estimation_time\"], \n",
    "                                                            loglik, sim_loglik, loglik_hyp, \n",
    "                                                            alpha_rmse, beta_rmse, params_resps_rmse, Omega_rmse))\n",
    "fw.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
